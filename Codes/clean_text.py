import unicodedata

# âœ… Allowed characters (Yoruba + English)
allowed_chars = set(
    "AÃÃ€EÃ‰Ãˆáº¸áº¸Ìáº¸Ì€IÃÃŒOÃ“Ã’á»Œá»ŒÌá»ŒÌ€UÃšÃ™"
    "aÃ¡Ã eÃ©Ã¨áº¹áº¹Ìáº¹Ì€iÃ­Ã¬oÃ³Ã²á»á»Ìá»Ì€uÃºÃ¹"
    "á¹¢á¹£"
    "ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz"
    ".,!?;:'\"()[]{}-â€“â€”â€¦ \n"
)

# ğŸ”„ Optional: map similar characters to Yoruba equivalents
replacement_map = {
    'Ã§': 'á¹£',
    'Ã±': 'n',
    'Ã£': 'an',
    'Ãµ': 'on',
    'Ã¢': 'a',
    'Ãª': 'e',
    'Ã®': 'i',
    'Ã´': 'o',
    'Ã»': 'u',
    'Ã¤': 'a',
    'Ã«': 'e',
    'Ã¯': 'i',
    'Ã¶': 'o',
    'Ã¼': 'u',
    'Ã¿': 'i',
    'Å¾': 'á¹£',
    'Å›': 'á¹£',
    ' ': ' ',  # preserve space
    '\n': '\n' # preserve newline
}

def sanitize_text(text):
    result = []
    for char in text:
        if char in allowed_chars:
            result.append(char)
        elif char in replacement_map:
            result.append(replacement_map[char])
        else:
            # Try to normalize and strip accents
            normalized = unicodedata.normalize('NFD', char)
            stripped = ''.join(c for c in normalized if unicodedata.category(c) != 'Mn')
            # If stripped version is allowed, use it
            if stripped in allowed_chars:
                result.append(stripped)
            else:
                # Otherwise, replace with a placeholder or remove
                result.append('')
    return ''.join(result)

# ğŸ“‚ Read and sanitize file
def process_file(input_path, output_path):
    with open(input_path, 'r', encoding='utf-8') as f:
        original_text = f.read()
    cleaned_text = sanitize_text(original_text)
    with open(output_path, 'w', encoding='utf-8') as f:
        f.write(cleaned_text)

# ğŸ§ª Example usage
process_file('3_final_segmented_final_merged_output.txt', 'yoruba_cleaned.txt')
